model_type: "lm"
d_model: 128
num_heads: 4
d_ff: 512
num_layers: 2
seq_length: 128
batch_size: 32
learning_rate: 0.001
weight_decay: 0.01
epochs: 50
dropout: 0.1
seed: 42
warmup_steps: 1000
grad_clip: 1.0
save_dir: "checkpoints"
results_dir: "results"
data_dir: "data"
log_interval: 100
eval_interval: 500
save_interval: 10
use_positional_encoding: true
use_residual: true
use_layer_norm: true
